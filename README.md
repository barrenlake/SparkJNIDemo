# SparkJNIDemo


> 注：为方便起见，以下所有文件均在同一目录
## 1 创建Native文件（.so）

1.1 创建PlusJNI.scala

```
class PlusJNI {
// 定义native 方法
  @native def plus(key1: Int, key2:Int): Int
}

```
1.2 编译PlusJNI.scala， 生成PlusJNI.h
```
// 编译PlusJNI.scala, 生成PlusJNI.class
scalac PlusJNI.java

// 生成PlusJNI.h
javah -cp . PlusJNI
```
生成的 MathJNI.h的内容如下所示：
```
/* DO NOT EDIT THIS FILE - it is machine generated */
#include <jni.h>
/* Header for class PlusJNI */

#ifndef _IncludedMathJNI
#define _Included_PlusJNI
#ifdef __cplusplus
extern "C" {
#endif
/*
 * Class:     PlusJNI
 * Method:    plus
 * Signature: (II)I
 */
JNIEXPORT jint JNICALL Java_PlusJNI_plus
  (JNIEnv *, jobject, jint, jint);

#ifdef __cplusplus
}
#endif
#endif

```

1.3 创建plus.c 实现PlusJNI.h

```
#include <jni.h>
#include "PlusJNI.h"
#include <stdio.h>
// 两参数相加
JNIEXPORT jint JNICALL Java_PlusJNI_plus
    (JNIEnv *, jobject jobj, jint j1, jint j2)
    {
        return j1 + j2;
    }

```
1.4 编译plus.c 生成libplus_jni.so
```
gcc -shared -fpic -I$JAVA_HOME/include -I$JAVA_HOME/include/linux plus.c -o libplus_jni.so
```

1.5 编译本地方法测试libplus_jni.so
```
// Test.scala
object Test {
  def main(args: Array[String]): Unit = {
    // 加载本地库，参数为libplus_jni.so中lib后面部分plus_jni
    System.loadLibrary("plus_jni")
    val plus = new PlusJNI()
    plus.plus(1, 1)
  }
}

```
运行该方法时会抛出如下异常：
```
java.lang.UnsatisfiedLinkError: no plus in java.library.path
	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1867)
	at java.lang.Runtime.loadLibrary0(Runtime.java:870)
	at java.lang.System.loadLibrary(System.java:1122)
	at Test$.main(Test.scala:3)
	at Test.main(Test.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at scala.reflect.internal.util.ScalaClassLoader$$anonfun$run$1.apply(ScalaClassLoader.scala:70)
	at scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)
	at scala.reflect.internal.util.ScalaClassLoader$URLClassLoader.asContext(ScalaClassLoader.scala:101)
```

通过如下命令指定本地库位置后可正常执行
```
//指定本地库位置， "."为当前工作目录（相对Test文件而言）
scala -cp . -Djava.library.path=.  Test

```

## 2 创建Spark 应用

2.1 添加Maven Spark依赖  
该文件中的依赖依应用所需添加
```
    <dependencies>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_2.11</artifactId>
            <version>2.2.0</version>
        </dependency>

    </dependencies>

```

2.2 Spark调用JNI应用实现

```
import org.apache.spark.{SparkConf, SparkContext}

class SparkTest {

}

object SparkTest {
  def main(args: Array[String]): Unit = {
    val conf = new SparkConf().setAppName("chen-test").setMaster("local")
    val sc = new SparkContext(conf)
    // 创建rdd并分成两个Partition
    val rdd = sc.parallelize(Seq(1,2,3,4,5,6), 2) 
        //使用mapPartition按分区进行处理，每个分区加载一次native库；  
        //此处若直接使用map,则会每处理一个数据项加载一次native库，开销较大；  
        //且生成plusJNI对象较多，gc开销也较大。 
        .mapPartitions(p => {
           //plus_jni为libplus_jni.so的lib后面的名称。
            System.loadLibrary("plus_jni")
            val plusJNI = new PlusJNI()
            //对分区中的每个数据项做+10操作
            p.map(plusJNI.plus(_, 10))
        })
    rdd.collect().foreach(println(_))
  }
}

```

2.3 编译spark应用
```
mvn clean package 

生成jar,用于提交spark
```

2.4 提交Spark应用（on yarn）
```
spark-submit --queue root.nativelzo_test \  
--class SparkTest \  
--files ./src/main/scala/libplus_jni.so \  
--conf spark.executor.extraJavaOptions=-Djava.library.path=. \  
./target/sparkchen-1.0-SNAPSHOT.jar
```

其中：   

```
--files 会将native库上传至Executor的当前工作目录。
-Djava.library.path=. 指定Java Library的目录为当前工作目录，并通地spark.executor.extraJavaOptions 将参数引入JVM。

//也可使用其它形式的参数组合，此处仅为举例。
```

2.5 应用执行结果
```
[chenchengchen@host ~/sparkchen]$ spark-submit --queue root.nativelzo_test  \  
--class SparkTest  \  
--files ./src/main/scala/libplus_jni.so \  
--conf spark.executor.extraJavaOptions=-Djava.library.path=. \  
./target/sparkchen-1.0-SNAPSHOT.jar

Application Id: application_1508228032068_6076510, Tracking URL: http://bigdata_host.01:8088/proxy/application_1508228032068_6076510/
11                                          
12
13
14
15
16
```

